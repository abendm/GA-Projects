{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ames = pd.read_csv('data/ames_housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = corr.abs().unstack()\n",
    "c1[c1!=1].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(ames.SalePrice)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It looks like there may be a few houses that are major outliers.  Based on the correllation matrix above, it looks like OverallQual and GrLivArea are the most highly correlated with Sale Price, so I will investigate there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(ames.OverallQual, ames.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(ames.GrLivArea, ames.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames.SaleCondition.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It looks like there are 4 really odd houses where the relationship between GrLivArea and SalesPrice break down, so I'm planning to drop those from the model.  I realize I could also use the Log of sales price, but it seems like the vast majority of datapoints fit the non-log scale, so I'm making the judgment to just drop the weird looking data points.\n",
    "\n",
    "## This is a huge dataset, and I'm assuming you aren't asking us to make the best possible model, so below, I've pulled in enough features that I think are relevant and useful to a linear model.  I've also decided to simply drop nulls here since I want to see the overall improvement in the model by filling certain nulls with appropriate fills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ames_orig_X = ames[ames.GrLivArea<4000][['LotFrontage', 'LotArea', 'OverallQual', 'TotalBsmtSF', 'SalePrice',\n",
    "                    'GrLivArea', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'PoolArea', 'YrSold'\n",
    "                   ]].dropna()\n",
    "ames_orig_y = ames_orig_X.SalePrice\n",
    "ames_orig_X = ames_orig_X.drop('SalePrice', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "X_train, X_test, y_train, y_test = train_test_split(ames_orig_X, ames_orig_y)\n",
    "lr.fit(X_train, y_train)\n",
    "orig_pred = lr.predict(X_test)\n",
    "print('RMSE is {:.4f}'.format(np.sqrt(mean_squared_error(y_test, orig_pred))))\n",
    "print('R-squared is {:.4f}'.format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Without any feature engineering or filling, the model seems to be OK.  I tested my hypothesis above and using log of sales price without first filtering by GrLivArea makes a big improvement, but once I filtered by GrLivArea< 4000, the improvement became somewhat negligible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames['PoolArea'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now I'll fill in nulls for some of the categorical values that I plan to use in my model (or as components of engineered features).  For categoricals that I'm encoding as ordinals, I'll just fill the NaNs as zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ames = pd.read_csv('data/ames_housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ames['PoolQC'] = ames['PoolQC'].fillna('None')\n",
    "ames['Alley'] = ames['Alley'].fillna(\"None\")\n",
    "ames['FireplaceQu'] = ames['FireplaceQu'].fillna(\"None\")\n",
    "ames['MiscFeature'] = ames['MiscFeature'].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None    690\n",
       "Gd      380\n",
       "TA      313\n",
       "Fa       33\n",
       "Ex       24\n",
       "Po       20\n",
       "Name: FireplaceQu, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ames.FireplaceQu.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames = ames.replace({\"BsmtCond\": {None:0, \"No\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5}})\n",
    "ames = ames.replace({\"BsmtQual\" : {None: 0, \"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5}})\n",
    "ames = ames.replace({\"GarageQual\" : {None: 0, \"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5}})\n",
    "ames = ames.replace({\"GarageCond\" : {None: 0, \"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5}})\n",
    "ames = ames.replace({\"PoolQC\" : {\"None\" : 0, \"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5}})\n",
    "ames = ames.replace({\"FireplaceQu\" : {\"None\" : 0, \"No\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 6 columns):\n",
      "BsmtCond       1460 non-null int64\n",
      "BsmtQual       1460 non-null int64\n",
      "GarageQual     1460 non-null int64\n",
      "GarageCond     1460 non-null int64\n",
      "PoolQC         1460 non-null int64\n",
      "FireplaceQu    1460 non-null int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 68.5 KB\n"
     ]
    }
   ],
   "source": [
    "ames[['BsmtCond', 'BsmtQual', 'GarageQual', 'GarageCond', 'PoolQC', 'FireplaceQu']].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below are some (hopefully useful) engineered features.  There are plenty more I could imagine making, but I gather that the point of this assignment is merely to show that I understand the idea behind engineering features, which I think the below probably does.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames['TotalSF'] = ames.TotalBsmtSF + ames['1stFlrSF'] + ames['2ndFlrSF']\n",
    "ames['AboveGrRooms'] = ames.KitchenAbvGr + ames.BedroomAbvGr + ames.FullBath + ames.HalfBath\n",
    "ames['AgeSold'] = ames.YrSold - ames.YearRemodAdd #documentation says that Remodel age is same as YrBuilt if no remodel.\n",
    "ames['MSSubClass'] = ames['MSSubClass'].astype(str)\n",
    "ames['LotFrontage'] = ames['LotFrontage'].fillna(ames.LotFrontage.median()) #don't want to mess up distribution\n",
    "ames['LotMetric'] = ames['LotFrontage'] * ames['LotArea']\n",
    "ames['GarageOverall'] = ames['GarageCond'] * ames['GarageArea'] * ames['GarageCars'] * ames['GarageQual']\n",
    "ames['PoolOverall'] = ames['PoolArea'] * ames['PoolQC']\n",
    "ames['BasementOverall'] = ames['BsmtCond'] * ames['BsmtQual']\n",
    "ames['FireplaceOverall'] = ames.FireplaceQu * ames.Fireplaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 89 columns):\n",
      "Id                  1460 non-null int64\n",
      "MSSubClass          1460 non-null object\n",
      "MSZoning            1460 non-null object\n",
      "LotFrontage         1460 non-null float64\n",
      "LotArea             1460 non-null int64\n",
      "Street              1460 non-null object\n",
      "Alley               1460 non-null object\n",
      "LotShape            1460 non-null object\n",
      "LandContour         1460 non-null object\n",
      "Utilities           1460 non-null object\n",
      "LotConfig           1460 non-null object\n",
      "LandSlope           1460 non-null object\n",
      "Neighborhood        1460 non-null object\n",
      "Condition1          1460 non-null object\n",
      "Condition2          1460 non-null object\n",
      "BldgType            1460 non-null object\n",
      "HouseStyle          1460 non-null object\n",
      "OverallQual         1460 non-null int64\n",
      "OverallCond         1460 non-null int64\n",
      "YearBuilt           1460 non-null int64\n",
      "YearRemodAdd        1460 non-null int64\n",
      "RoofStyle           1460 non-null object\n",
      "RoofMatl            1460 non-null object\n",
      "Exterior1st         1460 non-null object\n",
      "Exterior2nd         1460 non-null object\n",
      "MasVnrType          1452 non-null object\n",
      "MasVnrArea          1452 non-null float64\n",
      "ExterQual           1460 non-null object\n",
      "ExterCond           1460 non-null object\n",
      "Foundation          1460 non-null object\n",
      "BsmtQual            1460 non-null int64\n",
      "BsmtCond            1460 non-null int64\n",
      "BsmtExposure        1422 non-null object\n",
      "BsmtFinType1        1423 non-null object\n",
      "BsmtFinSF1          1460 non-null int64\n",
      "BsmtFinType2        1422 non-null object\n",
      "BsmtFinSF2          1460 non-null int64\n",
      "BsmtUnfSF           1460 non-null int64\n",
      "TotalBsmtSF         1460 non-null int64\n",
      "Heating             1460 non-null object\n",
      "HeatingQC           1460 non-null object\n",
      "CentralAir          1460 non-null object\n",
      "Electrical          1459 non-null object\n",
      "1stFlrSF            1460 non-null int64\n",
      "2ndFlrSF            1460 non-null int64\n",
      "LowQualFinSF        1460 non-null int64\n",
      "GrLivArea           1460 non-null int64\n",
      "BsmtFullBath        1460 non-null int64\n",
      "BsmtHalfBath        1460 non-null int64\n",
      "FullBath            1460 non-null int64\n",
      "HalfBath            1460 non-null int64\n",
      "BedroomAbvGr        1460 non-null int64\n",
      "KitchenAbvGr        1460 non-null int64\n",
      "KitchenQual         1460 non-null object\n",
      "TotRmsAbvGrd        1460 non-null int64\n",
      "Functional          1460 non-null object\n",
      "Fireplaces          1460 non-null int64\n",
      "FireplaceQu         1460 non-null int64\n",
      "GarageType          1379 non-null object\n",
      "GarageYrBlt         1379 non-null float64\n",
      "GarageFinish        1379 non-null object\n",
      "GarageCars          1460 non-null int64\n",
      "GarageArea          1460 non-null int64\n",
      "GarageQual          1460 non-null int64\n",
      "GarageCond          1460 non-null int64\n",
      "PavedDrive          1460 non-null object\n",
      "WoodDeckSF          1460 non-null int64\n",
      "OpenPorchSF         1460 non-null int64\n",
      "EnclosedPorch       1460 non-null int64\n",
      "3SsnPorch           1460 non-null int64\n",
      "ScreenPorch         1460 non-null int64\n",
      "PoolArea            1460 non-null int64\n",
      "PoolQC              1460 non-null int64\n",
      "Fence               281 non-null object\n",
      "MiscFeature         1460 non-null object\n",
      "MiscVal             1460 non-null int64\n",
      "MoSold              1460 non-null int64\n",
      "YrSold              1460 non-null int64\n",
      "SaleType            1460 non-null object\n",
      "SaleCondition       1460 non-null object\n",
      "SalePrice           1460 non-null int64\n",
      "TotalSF             1460 non-null int64\n",
      "AboveGrRooms        1460 non-null int64\n",
      "AgeSold             1460 non-null int64\n",
      "LotMetric           1460 non-null float64\n",
      "GarageOverall       1460 non-null int64\n",
      "PoolOverall         1460 non-null int64\n",
      "BasementOverall     1460 non-null int64\n",
      "FireplaceOverall    1460 non-null int64\n",
      "dtypes: float64(4), int64(47), object(38)\n",
      "memory usage: 1015.2+ KB\n"
     ]
    }
   ],
   "source": [
    "ames.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Now I've added a few columns and created dummies.  Conceivably, I could create new engineered features with dummies (e.g., Heating (dummies) * HeatingQC (encoded ordinal)), but I could see the number of columns getting out of hand rather quickly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_improved = ames[ames['GrLivArea']<4000][['SalePrice', 'TotalSF','AboveGrRooms', 'AgeSold', 'MSSubClass', 'MSZoning', 'LotMetric',\n",
    "                      'Alley', 'GarageOverall', 'PoolOverall', 'BasementOverall', 'FireplaceOverall',\n",
    "                      'CentralAir', 'OverallQual', 'OverallCond', 'GrLivArea', 'TotRmsAbvGrd'\n",
    "                     ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1456 entries, 0 to 1459\n",
      "Data columns (total 17 columns):\n",
      "SalePrice           1456 non-null int64\n",
      "TotalSF             1456 non-null int64\n",
      "AboveGrRooms        1456 non-null int64\n",
      "AgeSold             1456 non-null int64\n",
      "MSSubClass          1456 non-null object\n",
      "MSZoning            1456 non-null object\n",
      "LotMetric           1456 non-null float64\n",
      "Alley               1456 non-null object\n",
      "GarageOverall       1456 non-null int64\n",
      "PoolOverall         1456 non-null int64\n",
      "BasementOverall     1456 non-null int64\n",
      "FireplaceOverall    1456 non-null int64\n",
      "CentralAir          1456 non-null object\n",
      "OverallQual         1456 non-null int64\n",
      "OverallCond         1456 non-null int64\n",
      "GrLivArea           1456 non-null int64\n",
      "TotRmsAbvGrd        1456 non-null int64\n",
      "dtypes: float64(1), int64(12), object(4)\n",
      "memory usage: 204.8+ KB\n"
     ]
    }
   ],
   "source": [
    "ames_improved.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_improved = pd.get_dummies(ames_improved, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1456 entries, 0 to 1459\n",
      "Data columns (total 34 columns):\n",
      "SalePrice           1456 non-null int64\n",
      "TotalSF             1456 non-null int64\n",
      "AboveGrRooms        1456 non-null int64\n",
      "AgeSold             1456 non-null int64\n",
      "LotMetric           1456 non-null float64\n",
      "GarageOverall       1456 non-null int64\n",
      "PoolOverall         1456 non-null int64\n",
      "BasementOverall     1456 non-null int64\n",
      "FireplaceOverall    1456 non-null int64\n",
      "OverallQual         1456 non-null int64\n",
      "OverallCond         1456 non-null int64\n",
      "GrLivArea           1456 non-null int64\n",
      "TotRmsAbvGrd        1456 non-null int64\n",
      "MSSubClass_160      1456 non-null uint8\n",
      "MSSubClass_180      1456 non-null uint8\n",
      "MSSubClass_190      1456 non-null uint8\n",
      "MSSubClass_20       1456 non-null uint8\n",
      "MSSubClass_30       1456 non-null uint8\n",
      "MSSubClass_40       1456 non-null uint8\n",
      "MSSubClass_45       1456 non-null uint8\n",
      "MSSubClass_50       1456 non-null uint8\n",
      "MSSubClass_60       1456 non-null uint8\n",
      "MSSubClass_70       1456 non-null uint8\n",
      "MSSubClass_75       1456 non-null uint8\n",
      "MSSubClass_80       1456 non-null uint8\n",
      "MSSubClass_85       1456 non-null uint8\n",
      "MSSubClass_90       1456 non-null uint8\n",
      "MSZoning_FV         1456 non-null uint8\n",
      "MSZoning_RH         1456 non-null uint8\n",
      "MSZoning_RL         1456 non-null uint8\n",
      "MSZoning_RM         1456 non-null uint8\n",
      "Alley_None          1456 non-null uint8\n",
      "Alley_Pave          1456 non-null uint8\n",
      "CentralAir_Y        1456 non-null uint8\n",
      "dtypes: float64(1), int64(12), uint8(21)\n",
      "memory usage: 189.1 KB\n"
     ]
    }
   ],
   "source": [
    "ames_improved.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now it's time to compare the old model to the new one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of Original Model is 33319.1825\n",
      "R-squared of Original Model is 0.8146\n"
     ]
    }
   ],
   "source": [
    "ames_orig_X = ames[ames.GrLivArea<4000][['LotFrontage', 'LotArea', 'OverallQual', 'TotalBsmtSF', 'SalePrice',\n",
    "                    'GrLivArea', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'PoolArea', 'YrSold'\n",
    "                   ]].dropna()\n",
    "ames_orig_y = ames_orig_X.SalePrice\n",
    "ames_orig_X = ames_orig_X.drop('SalePrice', axis=1)\n",
    "lr = LinearRegression()\n",
    "X_train, X_test, y_train, y_test = train_test_split(ames_orig_X, ames_orig_y)\n",
    "lr.fit(X_train, y_train)\n",
    "orig_pred = lr.predict(X_test)\n",
    "print('RMSE of Original Model is {:.4f}'.format(np.sqrt(mean_squared_error(y_test, orig_pred))))\n",
    "print('R-squared of Original Model is {:.4f}'.format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of Spiffy New Model is 31040.5008\n",
      "R-squared of Spiffy New Model is 0.8339\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "X_train, X_test, y_train, y_test = train_test_split(ames_improved.drop('SalePrice', axis=1), ames_improved.SalePrice)\n",
    "lr.fit(X_train, y_train)\n",
    "pred = lr.predict(X_test)\n",
    "print('RMSE of Spiffy New Model is {:.4f}'.format(np.sqrt(mean_squared_error(y_test, pred))))\n",
    "print('R-squared of Spiffy New Model is {:.4f}'.format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding some features seems to have improved the model somewhat.  Now it's time to see if scaling, using other models, and/or polynomial features can improve it more.\n",
    "\n",
    "# Also, after playing around a bit, it seems that with scaled X values, transforming sale price to the log of sale price makes more of a difference.  I must confess I don't understand *why* that's the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "scaler = MinMaxScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(ames_improved.drop('SalePrice', axis=1), np.log(ames_improved.SalePrice))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_scaled = LinearRegression()\n",
    "ridge_ames = Ridge(alpha=1)\n",
    "lasso_ames = Lasso()\n",
    "eNet_ames = ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 value is : 0.8564 \n",
      "The RMSE value is 0.1489\n"
     ]
    }
   ],
   "source": [
    "linear_scaled.fit(X_train_scaled, y_train)\n",
    "predictions = linear_scaled.predict(X_test_scaled)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "score = linear_scaled.score(X_test_scaled, y_test)\n",
    "print('The r2 value is : {:.4f}'.format(score), '\\nThe RMSE value is {:.4f}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 value is : 0.8780 \n",
      "The RMSE value is 0.1372\n"
     ]
    }
   ],
   "source": [
    "ridge_ames.fit(X_train_scaled, y_train)\n",
    "predictions = ridge_ames.predict(X_test_scaled)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "score = ridge_ames.score(X_test_scaled, y_test)\n",
    "print('The r2 value is : {:.4f}'.format(score), '\\nThe RMSE value is {:.4f}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 value is : -0.0013 \n",
      "The RMSE value is 0.3932\n"
     ]
    }
   ],
   "source": [
    "lasso_ames.fit(X_train_scaled, y_train)\n",
    "predictions = lasso_ames.predict(X_test_scaled)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "score = lasso_ames.score(X_test_scaled, y_test)\n",
    "print('The r2 value is : {:.4f}'.format(score), '\\nThe RMSE value is {:.4f}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 value is : -0.0013 \n",
      "The RMSE value is 0.3932\n"
     ]
    }
   ],
   "source": [
    "eNet_ames.fit(X_train_scaled, y_train)\n",
    "predictions = eNet_ames.predict(X_test_scaled)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "score = eNet_ames.score(X_test_scaled, y_test)\n",
    "print('The r2 value is : {:.4f}'.format(score), '\\nThe RMSE value is {:.4f}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13320915,  0.        , -0.00281001,  0.        ,  0.02255429,\n",
       "       -0.        ,  0.        ,  0.        ,  0.11682661,  0.        ,\n",
       "        0.        ,  0.        , -0.        , -0.        , -0.        ,\n",
       "        0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        0.        , -0.        , -0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "        0.        , -0.        ,  0.        ])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_ames.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10504906, -0.00733893, -0.04039272,  0.02003258,  0.06282615,\n",
       "       -0.00773938,  0.03189313,  0.02815681,  0.09190231,  0.02883661,\n",
       "        0.06898049, -0.00658998, -0.02543209, -0.0061238 , -0.01115786,\n",
       "       -0.01231133, -0.02725767, -0.00169547, -0.00326354, -0.02230555,\n",
       "       -0.00211388, -0.01320186, -0.00809402, -0.00483169, -0.00239059,\n",
       "       -0.01130244,  0.08046072,  0.03360815,  0.13882841,  0.08708537,\n",
       "        0.01230284,  0.00760962,  0.02051971])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_ames.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  So the act of scaling seems to have significantly improved the model, and the Ridge seems to have improved a little too, but I'm not really sure what's going on with the Lasso and Elastic Nets.  \n",
    "\n",
    "## For now, I'm going to just try and see what happens when I add polynomial features using a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline \n",
    "X_train, X_test, y_train, y_test = train_test_split(ames_improved.drop('SalePrice', axis=1), np.log(ames_improved.SalePrice))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 value is : 0.0436 \n",
      "The RMSE value is 0.3762\n"
     ]
    }
   ],
   "source": [
    "lm_pipe = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "lm_pipe.fit(X_train, y_train)\n",
    "predictions = lm_pipe.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "score = lm_pipe.score(X_test, y_test)\n",
    "print('The r2 value is : {:.4f}'.format(score), '\\nThe RMSE value is {:.4f}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 value is : -14.3847 \n",
      "The RMSE value is 0.2560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\linalg\\basic.py:223: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number: 1.934251277291456e-19\n",
      "  ' condition number: {}'.format(rcond), RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "ridge_pipe = make_pipeline(PolynomialFeatures(degree=2), Ridge())\n",
    "ridge_pipe.fit(X_train, y_train)\n",
    "predictions = ridge_pipe.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "score = ridge_pipe.score(X_test_scaled, y_test)\n",
    "print('The r2 value is : {:.4f}'.format(score), '\\nThe RMSE value is {:.4f}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 value is : -7.0033 \n",
      "The RMSE value is 0.1829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lasso_pipe = make_pipeline(PolynomialFeatures(degree=2), Lasso(alpha=1)) #I played around here with a bunch of alphas.\n",
    "lasso_pipe.fit(X_train, y_train)\n",
    "predictions = lasso_pipe.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "score = lasso_pipe.score(X_test_scaled, y_test)\n",
    "print('The r2 value is : {:.4f}'.format(score), '\\nThe RMSE value is {:.4f}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  I'm guessing here that I'm misinterpreting what [model].score() is returning, since it seems like the \"scores\" of different models vary widely even though the RMSE seems to be improving."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
